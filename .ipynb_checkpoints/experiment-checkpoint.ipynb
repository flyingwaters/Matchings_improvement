{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入tools 生成的possible matchings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matchings_path = \"./dataset/employee.json\"\n",
    "answers_path = \"./dataset/employee_ans.json\"\n",
    "matchings_path = \"./dataset/author.json\"\n",
    "answers_path = \"./dataset/author_ans.json\"\n",
    "# matchings_path = \"./dataset/purchase.json\"\n",
    "# answers_path = \"./dataset/purchase_ans.json\"\n",
    "dataset_name = \"author\"\n",
    "# dataset_name = \"employee\"\n",
    "\n",
    "#LLM 预测准确率\n",
    "p_w = 0.917\n",
    "api_use = False\n",
    "# 每个token 一个\n",
    "budget = 35 # 单位为 price of one token  \n",
    "total_turns =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fact import FactSet\n",
    "from llm_api import gpt_check\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "with open(matchings_path, \"r\") as f:\n",
    "    content = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 chatgpt 的 tokenzier，用于估计correspondence 的cost func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process 统计，factset 需要的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(content):\n",
    "    import numpy as np\n",
    "    c_set = content[\"correspondence_set\"]\n",
    "    # chatgpt 的tokens 的num list\n",
    "    len_list = [len(encoding.encode(i[0][1]+i[1][1])) for i in c_set]\n",
    "    len_list.sort()\n",
    "    least_len = sum(len_list[:3])\n",
    "    matchings = content[\"matchings\"]\n",
    "    Views = []\n",
    "    for match in matchings:\n",
    "        view = []\n",
    "        for c in c_set:\n",
    "            if c in match:\n",
    "                view.append(1)\n",
    "            else:\n",
    "                view.append(0)\n",
    "        Views.append(view)\n",
    "    return np.array(Views), np.array(content[\"prob_all\"]), np.array(len_list), least_len, sum(len_list), c_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理后生成 facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_cost:  9 note that budget of each round must > 9 and < 51:\n"
     ]
    }
   ],
   "source": [
    "facts, prob, len_list, least_len, sum_c, c_set = process(content)\n",
    "print(\"max_cost: \", least_len, f\"note that budget of each round must > {least_len} and < {sum_c}:\")\n",
    "ex_fact = FactSet(facts=facts, prior_p=prob, ground_true=2, len_list=len_list)\n",
    "random_fact = FactSet(facts=facts, prior_p=prob, ground_true=2, len_list=len_list)\n",
    "brute_fact = FactSet(facts=facts, prior_p=prob, ground_true=2, len_list=len_list)\n",
    "heuristic_fact = FactSet(facts=facts, prior_p=prob, ground_true=2, len_list=len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selector to select correspondence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query import QuerySelector, BaseQuerySelector, GreedyQuerySelector,RandomQuerySelector, HeuristicQuerySelector\n",
    " # 对应fact1, 3是0.8, 0.\n",
    "query_selector = GreedyQuerySelector()\n",
    "# selection_idxes, sub_facts, h = query_selector.select(ex_fact, 2, accuracy, cost_func=2)\n",
    "random_selector = RandomQuerySelector()\n",
    "base_selector = BaseQuerySelector()\n",
    "h_selector = HeuristicQuerySelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM答案dict\n",
    "## 由于数量问题，模拟实验，从web chatgpt端，得到所有的correpspondence 验证答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(answers_path, \"r\") as f:\n",
    "    ans_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_len = ex_fact.num_fact()\n",
    "# 计算p(A_T) 和 P(A_T|v) 需要的LLM array:acc \n",
    "acc = np.array([[p_w for i in range(c_len)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_p_caculate(prior_p, p_a_v, p_a):\n",
    "    return prior_p*p_a_v / p_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  our近似算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx:8.27517557144165 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "approx_h_list=[ex_fact.compute_entropy()]\n",
    "\n",
    "cost_sum = 0\n",
    "turns = total_turns \n",
    "start = time.time()\n",
    "while turns>0:\n",
    "    selection_idxes, sub_facts, h = query_selector.select(ex_fact, budget, acc, cost_func=2)\n",
    "    if api_use:\n",
    "         ans = [1 if gpt_check(ix_r, c_set)==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    else:\n",
    "        ans = [1 if ans_list[ix_r]==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    p_a,p_a_v = ex_fact.compute_ans_p(ans, selection_idxes, acc)\n",
    "    p_post = ex_fact.get_prior_p()*p_a_v/p_a\n",
    "    ex_fact.set_prior_p(p_post)\n",
    "    approx_h_list.append(ex_fact.compute_entropy())\n",
    "    turns -=1\n",
    "end = time.time()\n",
    "\n",
    "approx_timecost = end - start\n",
    "print(\"approx:{} s\".format(approx_timecost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_h_list = []\n",
    "cost_list = []\n",
    "p_prior = random_fact.get_prior_p()\n",
    "for _ in range(100):\n",
    "    cost_sum_r = 0\n",
    "    random_fact.set_prior_p(p_prior)\n",
    "    turns_r=total_turns\n",
    "    random_h_list=[random_fact.compute_entropy()]\n",
    "    random_selection_idxes, _, _  =  random_selector.select(random_fact, budget, acc)\n",
    "    while turns_r>0:\n",
    "      \n",
    "        if api_use:\n",
    "            ans_r = [1 if gpt_check(ix_r, c_set)==\"yes\" else 0 for ix_r in random_selection_idxes]\n",
    "        else:\n",
    "            ans_r = [1 if ans_list[ix_r]==\"yes\" else 0 for ix_r in random_selection_idxes]\n",
    "        p_a_r,p_a_v_r = random_fact.compute_ans_p(ans_r, random_selection_idxes, acc)\n",
    "        p_post = random_fact.get_prior_p()*p_a_v / p_a\n",
    "        random_fact.set_prior_p(p_post)\n",
    "        random_h_list.append(random_fact.compute_entropy())\n",
    "        turns_r -=1\n",
    "    all_h_list.append(random_h_list)\n",
    "    cost_list.append(cost_sum_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute:1785.5654842853546 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "brute_h_list=[brute_fact.compute_entropy()]\n",
    "cost_sum = 0\n",
    "turns = total_turns \n",
    "start = time.time()\n",
    "while turns>0:\n",
    "    selection_idxes, sub_facts, h = base_selector.select(brute_fact, budget, acc)\n",
    "    if api_use:\n",
    "         ans = [1 if gpt_check(ix_r, c_set)==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    else:\n",
    "        ans = [1 if ans_list[ix_r]==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    p_a,p_a_v = brute_fact.compute_ans_p(ans, selection_idxes, acc)\n",
    "    p_post = brute_fact.get_prior_p()*p_a_v / p_a\n",
    "    brute_fact.set_prior_p(p_post)\n",
    "    brute_h_list.append(brute_fact.compute_entropy())\n",
    "    turns -=1\n",
    "end = time.time()\n",
    "\n",
    "brute_timecost = end - start\n",
    "print(\"brute:{} s\".format(brute_timecost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heuristic: 219.80209803581238\n"
     ]
    }
   ],
   "source": [
    "heuristic_h_list=[heuristic_fact.compute_entropy()]\n",
    "cost_sum = 0\n",
    "turns = total_turns \n",
    "start = time.time()\n",
    "while turns>0:\n",
    "    selection_idxes, sub_facts, h = h_selector.select(heuristic_fact, budget, acc, max_iters=10, cost_func=2)\n",
    "    if api_use:\n",
    "         ans = [1 if gpt_check(ix_r, c_set)==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    else:\n",
    "        ans = [1 if ans_list[ix_r]==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    p_a,p_a_v = heuristic_fact.compute_ans_p(ans, selection_idxes, acc)\n",
    "    p_post = heuristic_fact.get_prior_p()*p_a_v / p_a\n",
    "    heuristic_fact.set_prior_p(p_post)\n",
    "    heuristic_h_list.append(heuristic_fact.compute_entropy())\n",
    "    turns -=1\n",
    "end = time.time()\n",
    "\n",
    "heuristic_timecost = end - start\n",
    "print(\"heuristic: {}\".format(heuristic_timecost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approx_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0179569806623436,\n",
       " 0.04850071520375093,\n",
       " 0.0007121559136391639,\n",
       " 8.475355387646001e-06,\n",
       " 9.107752459490967e-08,\n",
       " 9.234666681931895e-10,\n",
       " 9.018120191382035e-12,\n",
       " 8.574764637194502e-14,\n",
       " 7.799761819158998e-16,\n",
       " 7.18871683042066e-18,\n",
       " 6.543745203618148e-20,\n",
       " 5.897074022670564e-22,\n",
       " 5.270388787733485e-24,\n",
       " 4.677591301815171e-26,\n",
       " 4.12690498430247e-28,\n",
       " 3.6224734142156624e-30,\n",
       " 3.1655665183593934e-32,\n",
       " 2.7554840150173155e-34,\n",
       " 2.3902261481261242e-36,\n",
       " 2.0669863201285002e-38,\n",
       " 1.7825080936416507e-40]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_h_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.017956980662346,\n",
       " 0.3828448384937168,\n",
       " 0.36644419493071767,\n",
       " 0.3662069399609961,\n",
       " 0.3662041267304737,\n",
       " 0.36620409653173885,\n",
       " 0.36620409622571926,\n",
       " 0.36620409622273153,\n",
       " 0.3662040962227031,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267,\n",
       " 0.36620409622270267]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = np.array(all_h_list)\n",
    "random_h_l = n.mean(axis=0, keepdims=True)\n",
    "random_h_l = random_h_l.tolist()[0]\n",
    "random_h_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0179569806623436,\n",
       " 0.049749981869701455,\n",
       " 0.0007123050109495532,\n",
       " 8.475355408715273e-06,\n",
       " 9.107752397507204e-08,\n",
       " 9.234665455268117e-10,\n",
       " 9.018120180378155e-12,\n",
       " 8.57476463626294e-14,\n",
       " 7.799761819123783e-16,\n",
       " 7.188716830477893e-18,\n",
       " 6.543745203618105e-20,\n",
       " 5.897074022670538e-22,\n",
       " 5.270388787733483e-24,\n",
       " 4.6775913018151874e-26,\n",
       " 4.126904984302471e-28,\n",
       " 3.6224734142156736e-30,\n",
       " 3.1655665183594027e-32,\n",
       " 2.7554840150173146e-34,\n",
       " 2.3902261481261232e-36,\n",
       " 2.0669863201285e-38,\n",
       " 1.7825080936416497e-40]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_h_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0179569806623436,\n",
       " 0.04974685119757438,\n",
       " 0.0007123028671739986,\n",
       " 8.475355389340578e-06,\n",
       " 9.107751111090552e-08,\n",
       " 9.234665444514373e-10,\n",
       " 9.018120180290755e-12,\n",
       " 8.574764636254668e-14,\n",
       " 7.799761819081175e-16,\n",
       " 7.18871683041474e-18,\n",
       " 6.543745203617627e-20,\n",
       " 5.897074022670519e-22,\n",
       " 5.270388787733478e-24,\n",
       " 4.677591301815169e-26,\n",
       " 4.126904984302467e-28,\n",
       " 3.62247341421566e-30,\n",
       " 3.165566518359391e-32,\n",
       " 2.7554840150173134e-34,\n",
       " 2.3902261481261222e-36,\n",
       " 2.0669863201284986e-38,\n",
       " 1.7825080936416495e-40]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataset = \"output\"\n",
    "def save_h_file(approx_name_f,random_f, brute_name_f, heuristic_name_f, approx_ob, random_ob, brute_ob, heuristic_ob):\n",
    "    with open(f\"./{dataset}/\"+approx_name_f, \"w\") as f:\n",
    "        json.dump(approx_ob, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    with open(f\"./{dataset}/\"+random_f, \"w\") as w:\n",
    "        json.dump(random_ob, w, indent=2, ensure_ascii=False)\n",
    "        \n",
    "    with open(f\"./{dataset}/\"+brute_name_f, \"w\") as f2:\n",
    "        json.dump(brute_ob, f2, indent=2, ensure_ascii=False)\n",
    "        \n",
    "    with open(f\"./{dataset}/\"+ heuristic_name_f, \"w\") as f3:\n",
    "        json.dump(heuristic_ob, f3, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx = {\"entropy\":approx_h_list, \"timecost\":approx_timecost, \"prob\":list(ex_fact.get_prior_p())}\n",
    "random = {\"entropy\":random_h_list, \"timecost\":0, \"prob\":list(random_fact.get_prior_p())}\n",
    "brute = {\"entropy\":brute_h_list, \"timecost\":brute_timecost, \"prob\":list(brute_fact.get_prior_p())}\n",
    "heuristic = {\"entropy\":heuristic_h_list, \"timecost\":heuristic_timecost, \"prob\":list(heuristic_fact.get_prior_p())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"turns_{total_turns}\" + \"_budget={}_{}\"\n",
    "save_h_file(name.format(budget,f\"{dataset_name}_approx.json\"), name.format(budget,f\"{dataset_name}_random.json\"),\n",
    "            name.format(budget, f\"{dataset_name}_heuristic.json\"), name.format(budget, f\"{dataset_name}_brute.json\"),\n",
    "            approx, random, heuristic, brute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
