{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from valentine import valentine_match, valentine_metrics\n",
    "from valentine.algorithms import Coma, Cupid,DistributionBased,JaccardLevenMatcher,SimilarityFlooding\n",
    "\n",
    "from improve_tool import neg_entropy, generate_matchings, inconsistent_or_consistent, p_ans, p_ans_v, cost_func, p_v_ans\n",
    "import pprint\n",
    "import math\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "path1 = \"./data/purchase1.csv\"\n",
    "path2 = \"./data/purchase2.csv\"\n",
    "# path1 = \"./data/authors1.csv\"\n",
    "# path2 = \"./data/authors2.csv\"\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)\n",
    "c_matcher = Coma(max_n=3, strategy=\"COMA_OPT\")\n",
    "cu_matcher = Cupid()\n",
    "distribution_based_matcher = DistributionBased()\n",
    "jl_matcher = JaccardLevenMatcher()\n",
    "sf_matcher = SimilarityFlooding()\n",
    "matcher_list = [c_matcher, cu_matcher, jl_matcher]\n",
    "\n",
    "match_list = []\n",
    "for idx,matcher in enumerate(matcher_list): \n",
    "    matches = valentine_match(df1, df2, matcher)\n",
    "    iter_keys = list(matches.keys())\n",
    "    for c in iter_keys:\n",
    "        matches[((c[0][0], c[0][1].strip()), (c[1][0], c[1][1].strip()))] = matches.pop(c)\n",
    "        if idx == 1:\n",
    "            if matches[((c[0][0], c[0][1].strip()), (c[1][0], c[1][1].strip()))]<0.82:\n",
    "                matches.pop(((c[0][0], c[0][1].strip()), (c[1][0], c[1][1].strip())))\n",
    "    match_list.append(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('table_1', 'Delivery Date'), ('table_2', 'delivery date')): 1.0,\n",
       " (('table_1', 'Total Price'),\n",
       "  ('table_2', 'product price')): 0.9555555555555555,\n",
       " (('table_1', 'Order status'),\n",
       "  ('table_2', 'current status')): 0.9356643356643357,\n",
       " (('table_1', 'Unit Price'), ('table_2', 'product price')): 0.9111111111111112,\n",
       " (('table_1', 'Application Date'),\n",
       "  ('table_2', 'delivery date')): 0.9076923076923078,\n",
       " (('table_1', 'Product'), ('table_2', 'product name')): 0.8857142857142857,\n",
       " (('table_1', 'Product ID'), ('table_2', 'ID')): 0.8588235294117648,\n",
       " (('table_1', 'Purchasing Department'),\n",
       "  ('table_2', 'Application Department')): 0.8500000000000001,\n",
       " (('table_1', 'Product'),\n",
       "  ('table_2', 'product requirement')): 0.8400000000000001,\n",
       " (('table_1', 'Product'), ('table_2', 'product price')): 0.8400000000000001,\n",
       " (('table_1', 'Supplier Name'),\n",
       "  ('table_2', 'Supplier Company')): 0.8400000000000001,\n",
       " (('table_1', 'Order ID'), ('table_2', 'ID')): 0.8400000000000001,\n",
       " (('table_1', 'Purchasing Manager'),\n",
       "  ('table_2', 'Order Manager')): 0.835294117647059,\n",
       " (('table_1', 'Supplier Name'),\n",
       "  ('table_2', 'product name')): 0.8342857142857143,\n",
       " (('table_1', 'Supplier Name'),\n",
       "  ('table_2', 'Supplier Company candidate')): 0.8293333333333333,\n",
       " (('table_1', 'Actual delivery quantity'),\n",
       "  ('table_2', 'delivery date')): 0.8240000000000001,\n",
       " (('table_1', 'Order ID'),\n",
       "  ('table_2', 'purchasing number')): 0.8214932126696832}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def gen_info(matches):\n",
    "    num = len(matches)    \n",
    "    key1 = [i[0] for i in matches.keys()]\n",
    "    a = Counter(key1)\n",
    "    num_match = 1\n",
    "    for key in a.keys():\n",
    "        num_match*=a[key]\n",
    "    print(\"num of matches: \",num_match)\n",
    "    \n",
    "    matchings, prob, correspondences = generate_matchings(matches, a, num_match)\n",
    "    return matchings, prob, correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_matchings(matchings, prob):\n",
    "    s = matchings[0]\n",
    "    for i in matchings[1:]:\n",
    "        s.extend(i)\n",
    "    s_p = prob[0]\n",
    "    for j in prob[1:]:\n",
    "        s_p.extend(j)\n",
    "    sum_p = 0 \n",
    "    for p in s_p:\n",
    "        sum_p+=p\n",
    "    s_p = [p_i/sum_p for p_i in s_p]\n",
    "    return s,s_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correspondence_info(matchings, prob):\n",
    "    correspondences_list = []\n",
    "    for matching in matchings:\n",
    "        for c in matching:\n",
    "            if c not in correspondences_list:\n",
    "                correspondences_list.append(c)\n",
    "    \n",
    "    c_prob = []\n",
    "    for c in correspondences_list:\n",
    "        t_p = 0 \n",
    "        for idx,m in enumerate(matchings):\n",
    "            if c in m:\n",
    "                t_p+=prob[idx]\n",
    "        c_prob.append(t_p)\n",
    "        \n",
    "    assert len(correspondences_list)==len(c_prob)\n",
    "    return correspondences_list, c_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of matches:  4\n",
      "num of matches:  18\n",
      "num of matches:  1\n"
     ]
    }
   ],
   "source": [
    "m_l,p_l = [],[]\n",
    "for i in match_list:\n",
    "    matchings,prob,c_s = gen_info(i)\n",
    "    m_l.append(matchings)\n",
    "    p_l.append(prob)\n",
    "matches_all,prob_all = merge_matchings(m_l, p_l)\n",
    "assert len(matches_all) == len(prob_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, c_prob = correspondence_info(matches_all, prob_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save(file_name,save_dic):\n",
    "    path = f\"./data/{file_name}\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(save_dic,f, ensure_ascii=False, indent=2)\n",
    "\n",
    "data = {\"correspondence_set\":c, \"c_prob\":c_prob, \"matchings\":matches_all,\"prob_all\":prob_all}\n",
    "save(\"purchase.json\", data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
